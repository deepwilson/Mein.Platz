{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet_builder.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPmsADdjpRMF09nT3eBYbWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepwilson/repository/blob/main/_notebooks/2021-07-26-Resnet_builder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lutbdw7nGa3q"
      },
      "source": [
        "# \"Resnet builder from scratch\"\n",
        "> \"Building a resnet from scratch\"\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [deep_learning, resnet]\n",
        "- image: images/resnet.png\n",
        "- hide: false\n",
        "- search_exclude: true\n",
        "- metadata_key1: metadata_value1\n",
        "- metadata_key2: metadata_value2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuVUvsjR8T-L"
      },
      "source": [
        "#Resnet builder from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_Uekiiu8X3S"
      },
      "source": [
        "When building custom object detection pipelines, there is often a need to build/modify existing backbone networks. \n",
        "\n",
        "Resnet is a network that is commonly used in such models.\n",
        "\n",
        "However, once you modify the structure it gets difficult to use pre-trained weights.\n",
        "\n",
        "In this article I'll try to make the process easier by building a resnet from scratch.\n",
        "\n",
        "I use the naming convention of pre-trained keras networks to make the transfer easier.\n",
        "\n",
        "Once the model has been modified as per the usecase, we can copy the remaining weights from a pre-trained model(whichever applicable) \n",
        "\n",
        "Features:\n",
        "- Concise code\n",
        "- Simple Architecture\n",
        "- Customizable\n",
        "- Keras pre-trained weights can be pasted to custom build\n",
        "- **Modify a resnet as you wish (cut down etc) and still be able to paste weights from a pre-trained resnet on remaining applicable layers!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Gda01j7pWZ"
      },
      "source": [
        "![](https://iq.opengenus.org/content/images/2020/03/Screenshot-from-2020-03-20-15-49-54.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvYP_0za0M6r"
      },
      "source": [
        "<!-- ![](https://cdn-5f733ed3c1ac190fbc56ef88.closte.com/wp-content/uploads/2019/07/ResNet50_architecture-1.png) -->\n",
        "\n",
        "<img src=\"https://cdn-5f733ed3c1ac190fbc56ef88.closte.com/wp-content/uploads/2019/07/ResNet50_architecture-1.png\" alt=\"drawing\" height=\"400\" width=100/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQdhXNUjoh6X"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruGpQzSNWdAL"
      },
      "source": [
        "## Building blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yae6bZ0o5t_z"
      },
      "source": [
        "class Basic_Block(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        X\n",
        "        |\n",
        "        |--skip_block\n",
        "        |     |\n",
        "        |     conv(3x3)->bn->relu \n",
        "        |     |\n",
        "        |     conv(3x3)->bn->relu\n",
        "        |- + -|\n",
        "        |\n",
        "        v\n",
        "    RELU( X(residual) + skip_block )\n",
        "\n",
        "    Basic_Block: resnet-18,34 -> shortcut connections skips 2 layers (skip_block)\n",
        "    Bottleneck_Block: resnet 50,101 etc ->  shortcut connections skips 3 layers (skip_block)\n",
        "    \n",
        "    yet to implement\n",
        "    \"\"\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPJKu52azn5_"
      },
      "source": [
        "class Bottleneck_Block(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "        X\n",
        "        |\n",
        "        |--skip_block\n",
        "        |     |\n",
        "        |     conv(1x1)->bn->relu \n",
        "        |     |\n",
        "        |     conv(3x3)->bn->relu\n",
        "        |     |\n",
        "        |     conv(1x1)->bn\n",
        "        |- + -|\n",
        "        |\n",
        "        v\n",
        "    RELU( X(residual) + skip_block )\n",
        "\n",
        "    Basic_Block: resnet-18,34 -> shortcut connections skips 2 layers (skip_block)\n",
        "    Bottleneck_Block: resnet 50,101 etc ->  shortcut connections skips 3 layers (skip_block)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_filters, modify_conv=True, stride=1, idx=[None,None]):\n",
        "        stage_idx, block_idx = [str(i) for i in idx] \n",
        "        super().__init__(name=f'RESNET_BLOCK_{stage_idx}_{block_idx}') #name=f'resnet_block_{stage_idx}_{block_idx}'\n",
        "        \n",
        "        self.num_filters = num_filters\n",
        "\n",
        "        self.conv_name_base =  f'conv{stage_idx}_block{block_idx}_' \n",
        "        self.bn_name_base = f'conv{stage_idx}_block{block_idx}_'\n",
        "\n",
        "        self.conv1 = Conv2D(filters=num_filters, kernel_size=1, strides=1, padding=\"same\", name=self.conv_name_base+'1_conv')\n",
        "        self.bn1 = BatchNormalization(epsilon=1.001e-5, name=self.bn_name_base+'1_bn')\n",
        "        \n",
        "        self.conv2 = Conv2D(filters=num_filters, kernel_size=3, strides=stride, padding=\"same\", name=self.conv_name_base+'2_conv')\n",
        "        self.bn2 = BatchNormalization(name=self.bn_name_base+'2_bn')\n",
        "\n",
        "        self.conv3 = Conv2D(filters=num_filters*4, kernel_size=1, strides=1, padding=\"same\", name=self.conv_name_base+'3_conv')\n",
        "        self.bn3 = BatchNormalization(name=self.bn_name_base+'3_bn')\n",
        "\n",
        "        self.relu = ReLU()\n",
        "\n",
        "        self.modify_conv = modify_conv\n",
        "        if self.modify_conv:\n",
        "            self.modify_conv_block = tf.keras.Sequential([\n",
        "                            Conv2D(filters=num_filters*4, kernel_size=1, strides=stride, name=self.bn_name_base+'0_conv'),\n",
        "                            BatchNormalization(name=self.bn_name_base+'0_bn')\n",
        "                            ])\n",
        "\n",
        "                \n",
        "\n",
        "    def call(self, x, training=None, **kwargs):\n",
        "\n",
        "        residual = x\n",
        "\n",
        "        if self.modify_conv:\n",
        "            residual = self.modify_conv_block(x)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "\n",
        "        out = Add()([residual, x])\n",
        "        out = self.relu(out)\n",
        "\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        return cfg \n",
        "\n",
        "    def summary(self):\n",
        "        x = Input(shape=(224,224,self.num_filters*4))\n",
        "        model = tf.keras.models.Model(inputs=[x], outputs=self.call(x))\n",
        "        return model.summary()\n",
        "\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irlhSeVBxwX3"
      },
      "source": [
        "class Build_ResNet(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, block_type, num_filters_list = [64,128,256,512], num_blocks=[3,4,6,3] ,num_classes=1000):\n",
        "        super().__init__()\n",
        "        self.expansion_factor = 4\n",
        "        self.num_filters_pre_block = 64\n",
        "        \n",
        "\n",
        "\n",
        "        self.resnet_stage_1 = tf.keras.Sequential([\n",
        "                            Conv2D(filters=64, kernel_size=7, strides=2, padding=\"valid\", name=\"conv1_conv\"),\n",
        "                            BatchNormalization(name=\"conv1_bn\"),\n",
        "                            ReLU(),\n",
        "                            MaxPool2D(pool_size=3, strides=2, padding=\"same\")\n",
        "                            ])\n",
        "        \n",
        "        self.resnet_stage_2 = self._make_resnet_stage(block_type,num_filters_list[0],num_blocks[0],stride=1,stage_idx=2)\n",
        "        self.resnet_stage_3 = self._make_resnet_stage(block_type,num_filters_list[1],num_blocks[1],stride=2,stage_idx=3)\n",
        "        self.resnet_stage_4 = self._make_resnet_stage(block_type,num_filters_list[2],num_blocks[2],stride=2,stage_idx=4)\n",
        "        self.resnet_stage_5 = self._make_resnet_stage(block_type,num_filters_list[3],num_blocks[3],stride=2,stage_idx=5)\n",
        "\n",
        "\n",
        "        self.avgpool = GlobalAveragePooling2D()\n",
        "        self.fc = Dense(units=num_classes, activation=tf.keras.activations.softmax, name=\"predictions\")\n",
        "        \n",
        "    \n",
        "    def _make_resnet_stage(self, block_type, num_filters, num_blocks, stride=1, stage_idx=None):\n",
        "        modify_conv = False\n",
        "\n",
        "        # tf.print(f\"stride:{stride},num_filters:{num_filters},num_filters_pre_block:{self.num_filters_pre_block},modify_conv:{modify_conv}\")\n",
        "        # if stride==2 or num_filters!= self.num_filters_pre_block*self.expansion_factor:\n",
        "        if stride==2 or self.num_filters_pre_block != num_filters*self.expansion_factor:\n",
        "            modify_conv=True\n",
        "            \n",
        "\n",
        "        residual_blocks = []\n",
        "        residual_blocks.append(block_type(num_filters, modify_conv, stride, idx=[stage_idx, 1]))\n",
        "        # tf.print(stage_idx,1, f\"num_filters:{num_filters}, modify_conv:{modify_conv}, stride:{stride}\")\n",
        "        self.num_filters_pre_block *= self.expansion_factor \n",
        "\n",
        "\n",
        "        modify_conv=False\n",
        "        for i in range(1,num_blocks):\n",
        "\n",
        "            residual_blocks.append(block_type(num_filters, modify_conv, stride=1, idx=[stage_idx, i+1]))\n",
        "            # tf.print(stage_idx,i+1, f\"num_filters:{num_filters}, modify_conv:{modify_conv}, stride:{stride}\")\n",
        "\n",
        "        resnet_stage = tf.keras.Sequential(residual_blocks)\n",
        "        return resnet_stage\n",
        "        \n",
        "\n",
        "    def call(self,x):\n",
        "\n",
        "        x = self.resnet_stage_1(x)\n",
        "        \n",
        "        x = self.resnet_stage_2(x, training=True)\n",
        "        x = self.resnet_stage_3(x, training=True)\n",
        "        x = self.resnet_stage_4(x, training=True)\n",
        "        x = self.resnet_stage_5(x, training=True)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        return cfg \n",
        "        \n",
        "    def summary(self):\n",
        "        x = Input(shape=(224, 224, 3))\n",
        "        model = Model(inputs=[x], outputs=self.call(x))\n",
        "        return model.summary()\n",
        "    \n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pydnaOSMWgx7"
      },
      "source": [
        "##Resnet model zoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN7vSpFiPdIf"
      },
      "source": [
        "class ResnetModels():\n",
        "    \"\"\"https://github1s.com/keras-team/keras-applications/blob/bc89834ed36935ab4a4994446e34ff81c0d8e1b7/keras_applications/resnet_common.py#L463\"\"\"\n",
        "    basic_block = Basic_Block\n",
        "    bottleneck_block = Bottleneck_Block\n",
        "    bottleneck_block_v2 = None\n",
        "    num_classes = 1000\n",
        "\n",
        "    def ResNet50(num_classes=num_classes):\n",
        "        block_type = ResnetModels.bottleneck_block\n",
        "        num_filters_list = [64,128,256,512]\n",
        "        num_blocks=[3,4,6,3]\n",
        "            \n",
        "        return Build_ResNet(block_type, \n",
        "                      num_filters_list=num_filters_list, \n",
        "                      num_blocks=num_blocks, \n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    def ResNet101(num_classes=num_classes):\n",
        "\n",
        "        block_type = ResnetModels.bottleneck_block\n",
        "        num_filters_list = [64,128,256,512]\n",
        "        num_blocks=[3,4,23,3]\n",
        "        \n",
        "        return Build_ResNet(block_type, \n",
        "                      num_filters_list=num_filters_list, \n",
        "                      num_blocks=num_blocks, \n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    def ResNet152(num_classes=num_classes):\n",
        "\n",
        "        block_type = ResnetModels.bottleneck_block\n",
        "        num_filters_list = [64,128,256,512]\n",
        "        num_blocks=[3,8,36,3]\n",
        "        \n",
        "        return Build_ResNet(block_type, \n",
        "                      num_filters_list=num_filters_list, \n",
        "                      num_blocks=num_blocks, \n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    def ResNet50V2(num_classes=num_classes):\n",
        "\n",
        "        block_type = ResnetModels.bottleneck_block_v2\n",
        "        num_filters_list = [64,128,256,512]\n",
        "        num_blocks=[3,4,6,3]\n",
        "        \n",
        "        return Build_ResNet(block_type, \n",
        "                      num_filters_list=num_filters_list, \n",
        "                      num_blocks=num_blocks, \n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    def ResNet101V2(num_classes=num_classes):\n",
        "\n",
        "        block_type = ResnetModels.bottleneck_block\n",
        "        num_filters_list = [64,128,256,512]\n",
        "        num_blocks=[3,4,23,3]\n",
        "        \n",
        "\n",
        "    def ResNet152V2(num_classes=num_classes):\n",
        "\n",
        "        block_type = ResnetModels.bottleneck_block\n",
        "        num_filters_list = [64,128,256,512]\n",
        "        num_blocks=[3,8,36,3]\n",
        "        \n",
        "        return Build_ResNet(block_type, \n",
        "                      num_filters_list=num_filters_list, \n",
        "                      num_blocks=num_blocks, \n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    def ResNeXt50(num_classes=num_classes):\n",
        "\n",
        "        block_type = ResnetModels.bottleneck_block\n",
        "        num_filters_list = [128,256,512, 1024]\n",
        "        num_blocks=[3,4,6,3]\n",
        "        \n",
        "        return Build_ResNet(block_type, \n",
        "                      num_filters_list=num_filters_list, \n",
        "                      num_blocks=num_blocks, \n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    def ResNeXt101(num_classes=num_classes):\n",
        "        block_type = ResnetModels.bottleneck_block\n",
        "        num_filters_list = [64,128,256,512]\n",
        "        num_blocks=[3,4,23,3]\n",
        "        \n",
        "        return Build_ResNet(block_type, \n",
        "                        num_filters_list=num_filters_list, \n",
        "                        num_blocks=num_blocks, \n",
        "                        num_classes=num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inIK4saZWjhb"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRxFyYGVPoyA",
        "outputId": "35f42d10-1f06-46ab-8608-e20b0142f5ea"
      },
      "source": [
        "model = ResnetModels.ResNet50(num_classes=1000)\n",
        "model.summary() #please ensure to run this line to build the model\n",
        "pre_trained_model = tf.keras.applications.ResNet50()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_46 (Sequential)   (None, 55, 55, 64)        9728      \n",
            "_________________________________________________________________\n",
            "sequential_48 (Sequential)   (None, 55, 55, 256)       220032    \n",
            "_________________________________________________________________\n",
            "sequential_50 (Sequential)   (None, 28, 28, 512)       1230336   \n",
            "_________________________________________________________________\n",
            "sequential_52 (Sequential)   (None, 14, 14, 1024)      7129088   \n",
            "_________________________________________________________________\n",
            "sequential_54 (Sequential)   (None, 7, 7, 2048)        14998528  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              2049000   \n",
            "=================================================================\n",
            "Total params: 25,636,712\n",
            "Trainable params: 25,583,592\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dgGLanB11My"
      },
      "source": [
        "assert len(pre_trained_model.get_weights())==len(model.get_weights()), \"dim_check\""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2_BZkOvWl17"
      },
      "source": [
        "## Modifying as per usecase\n",
        "\n",
        "Let us use only 1st 2 sequential blocks of the resnet-50 \n",
        "\n",
        "The remaming layers are discarded.\n",
        "\n",
        "After the modification, we will copy the weights of 1st 2 blocks from pre-trained n/w automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWb-2fvYXFpa",
        "outputId": "d98cfa71-3bb1-446a-fd88-2a44f26806ec"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f506cf9b810>,\n",
              " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f506d9d5b10>,\n",
              " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f506ad5d510>,\n",
              " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f506d88fb50>,\n",
              " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f506ad7f910>,\n",
              " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7f506ad66ed0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f506ad75350>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ1sYhsVTUe0",
        "outputId": "b51b0a4e-347b-4608-a870-765eb73a3c47"
      },
      "source": [
        "model= tf.keras.models.Sequential(model.layers[0:2])\n",
        "x = np.random.normal(size=(1, 224, 224, 3))\n",
        "x = tf.convert_to_tensor(x)\n",
        "model(x)\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_46 (Sequential)   (None, 55, 55, 64)        9728      \n",
            "_________________________________________________________________\n",
            "sequential_48 (Sequential)   (None, 55, 55, 256)       220032    \n",
            "=================================================================\n",
            "Total params: 229,760\n",
            "Trainable params: 226,816\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w56zpCV6XaYJ"
      },
      "source": [
        "Notice the number of parameters have reduced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edEbECIPW56n"
      },
      "source": [
        "dict_1 = {}\n",
        "for layer in pre_trained_model.layers:\n",
        "    # print(layer.name)\n",
        "    # print(\"*\"*80)\n",
        "    for weight in (layer.weights):\n",
        "        name = weight.name\n",
        "        # layer_type = name.split('/')[-1][:-2]\n",
        "        # print(name, weight.numpy().shape)\n",
        "        dict_1[name] = ( name, weight.numpy() )\n",
        "\n",
        "# for key,value in dict_1.items():\n",
        "#     print(key, len(value))   \n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev0lDY3oZwQo"
      },
      "source": [
        "dict_2 = {\"kernel\":[],\n",
        "         \"bias\":[],\n",
        "         \"gamma\":[],\n",
        "         \"beta\":[],\n",
        "         \"moving_mean\":[],\n",
        "         \"moving_variance\":[],\n",
        "         }"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHXF0i45FT7s"
      },
      "source": [
        "for layer in model.layers:\n",
        "    # print(layer.name)\n",
        "    # print(\"*\"*80)\n",
        "    for weight in (layer.weights):\n",
        "        name = weight.name\n",
        "        layer_type = name.split('/')[-1][:-2]\n",
        "        # print(name, weight.shape)\n",
        "        dict_2[layer_type].append((name, weight))\n",
        "\n",
        "# for key,value in dict_2.items():\n",
        "#     print(key, len(value))   \n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZzrQLSFKKH7"
      },
      "source": [
        "##Copy the weights from pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBSGhYvdDBK4",
        "outputId": "482fb677-9dc1-4608-e69e-79960503047a"
      },
      "source": [
        "for layer in model.layers:\n",
        "    # print(layer.name)\n",
        "    # print(\"*\"*80)\n",
        "    for weight in (layer.weights):\n",
        "        name = weight.name\n",
        "\n",
        "        if \"RESNET_BLOCK\" in name:\n",
        "            key = \"/\".join(name.split(\"/\")[1:]) # residual_block_v2_49/conv5_block1_2_bn/gamma:0 -> conv5_block1_2_bn/gamma:0\n",
        "        else:\n",
        "            key = name\n",
        "        # print(key, dict_1[key][1].shape)\n",
        "        pretrained_weight = dict_1[key][1]\n",
        "        # print(pretrained_weight)\n",
        "        print(weight.shape, pretrained_weight.shape)\n",
        "        weight.assign(pretrained_weight)\n",
        "        # dict_2[layer_type].append((name, weight))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 7, 3, 64) (7, 7, 3, 64)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(1, 1, 64, 64) (1, 1, 64, 64)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(3, 3, 64, 64) (3, 3, 64, 64)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(1, 1, 64, 256) (1, 1, 64, 256)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(1, 1, 64, 256) (1, 1, 64, 256)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(1, 1, 256, 64) (1, 1, 256, 64)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(3, 3, 64, 64) (3, 3, 64, 64)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(1, 1, 64, 256) (1, 1, 64, 256)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(1, 1, 256, 64) (1, 1, 256, 64)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(3, 3, 64, 64) (3, 3, 64, 64)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(1, 1, 64, 256) (1, 1, 64, 256)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(64,) (64,)\n",
            "(256,) (256,)\n",
            "(256,) (256,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vur3fe9EThIL",
        "outputId": "97e1984e-17c7-4bcc-b5b4-34fd5462fddc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_46 (Sequential)   (None, 55, 55, 64)        9728      \n",
            "_________________________________________________________________\n",
            "sequential_48 (Sequential)   (None, 55, 55, 256)       220032    \n",
            "=================================================================\n",
            "Total params: 229,760\n",
            "Trainable params: 226,816\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P-udUvK7Zv8"
      },
      "source": [
        "## References:\n",
        "- https://iq.opengenus.org/resnet50-architecture/\n",
        "- https://i.stack.imgur.com/gI4zT.png\n",
        "- https://arxiv.org/pdf/1512.03385.pdf\n",
        "- https://github.com/dyhan0920/PyramidNet-PyTorch/blob/master/resnet.py\n",
        "- https://github1s.com/keras-team/keras-applications/blob/bc89834ed36935ab4a4994446e34ff81c0d8e1b7/keras_applications/resnet_common.py#L463\n",
        "- https://colab.research.google.com/github/puneetsingla17/Resnet50-from-Scratch/blob/master/Residual%2BNetworks%2B-%2Bv2%20(1).ipynb\n",
        "- https://github.com/calmisential/TensorFlow2.0_ResNet/blob/master/models/residual_block.py\n"
      ]
    }
  ]
}