{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN & Linear Regression From Scratch: Iris Dataset\n",
    "> A step-by-step implementation of the k-Nearest Neighbours and Linear Regression algorithms using the standard Python libaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  .custom-images-style {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    align-content: stretch;\n",
    "    flex-wrap: wrap;\n",
    "    flex-direction: row;\n",
    "    text-decoration: none !important;\n",
    "  }\n",
    "  .custom-images-style img {\n",
    "    margin-right: 5px;\n",
    "    margin-left: 5px;\n",
    "    margin-bottom: 10px;\n",
    "  }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# importing required libraries\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import statistics\n",
    "import copy\n",
    "\n",
    "# set random seed\n",
    "random.seed('iris dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbours From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flowchart for implementing the kNN algorithm is shown below. Each step in the implementation will be wrapped in its own function for clarity.\n",
    "\n",
    "![kNN Flowchart](https://raw.githubusercontent.com/Outsiders17711/Mein.Platz/main/images/ipynb/knn_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "The dataset is contained in a .csv file. We will implement a function `DataLoader` that calls several child functions to load and cleanup the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_csv(filename):\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = csv.reader(file)\n",
    "\t\treturn [row for row in csv_reader if row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_features(dataset):\n",
    "    num_columns = len(dataset[0])\n",
    "\n",
    "    for row in dataset:\n",
    "        for column in range(num_columns-1):\n",
    "            row[column] = float(row[column].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_classes(dataset):\n",
    "    class_mappings = {}\n",
    "    for row in dataset:\n",
    "        _specie = row[-1]\n",
    "        if _specie not in class_mappings.keys():\n",
    "            class_mappings[_specie] = len(class_mappings)\n",
    "        row[-1] = class_mappings[_specie]\n",
    "\n",
    "    return class_mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_data(dataset):\n",
    "    num_features = len(dataset[0])-1\n",
    "    for i in range(num_features):\n",
    "        column_values = [row[i] for row in dataset]\n",
    "        column_min = min(column_values)\n",
    "        column_max = max(column_values)\n",
    "        \n",
    "        for row in dataset:\n",
    "            row[i] = (row[i] - column_min) / (column_max - column_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(filename):\n",
    "    dataset = _load_csv(filename)\n",
    "    _clean_features(dataset)\n",
    "    class_mappings = _map_classes(dataset)\n",
    "    _normalize_data(dataset)\n",
    "\n",
    "    return dataset, class_mappings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Algorithm\n",
    "\n",
    "Next, we implement the algorithm itself in a main function `kNN_Algorithm` that calls several child functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    num_features = len(row1)-1\n",
    "\n",
    "    for i in range(num_features):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return math.sqrt(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_k_neighbours(test_row, train_data, num_neighbours):\n",
    "    test_train_distances = []\n",
    "    for train_row in train_data:\n",
    "        _test_train_distance = _euclidean_distance(test_row, train_row)\n",
    "        test_train_distances.append([train_row, _test_train_distance])\n",
    "\n",
    "    test_train_distances.sort(key=lambda idx: idx[1])\n",
    "    return [test_train_distances[i][0] for i in range(num_neighbours)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_classification(test_row, train_data, num_neighbours):\n",
    "    nearest_neighbours =  _get_k_neighbours(test_row, train_data, num_neighbours)\n",
    "    nearest_classes = [neighbour[-1] for neighbour in nearest_neighbours]\n",
    "    predicted_class = max(set(nearest_classes), key=nearest_classes.count)\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_Algorithm(test_data, train_data, num_neighbours):\n",
    "    return [_predict_classification(test_row, train_data, num_neighbours) for test_row in test_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate kNN Algorithm\n",
    "\n",
    "Now, we can go ahead and evaluate the performance of the algorithm against the dataset. The evaluation will be implemented using the function `Evaluate_kNN_Algorithm` which calls several child functions to split the dataset into test/train samples and calculate accuracies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_train_split(dataset, test_ratio):\n",
    "    _dataset = copy.deepcopy(dataset)\n",
    "    random.shuffle(_dataset)\n",
    "\n",
    "    split_index = int(len(dataset) * test_ratio)\n",
    "    # Training data\n",
    "    test_sample = _dataset[0:split_index]\n",
    "    #Testing data\n",
    "    train_sample = _dataset[split_index:]\n",
    "\n",
    "    return test_sample, train_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cross_validation_split(dataset, num_groups):\n",
    "    dataset_groups = []\n",
    "    _dataset = copy.deepcopy(dataset)\n",
    "    group_size = int(len(_dataset) / num_groups)\n",
    "\n",
    "    for i in range(num_groups):\n",
    "        group = []\n",
    "        while len(group) < group_size:\n",
    "            idx = random.randrange(len(_dataset))\n",
    "            group.append(_dataset.pop(idx))\n",
    "        dataset_groups.append(group)\n",
    "\n",
    "    return dataset_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(test_sample, algorithm_predictions, class_mappings):\n",
    "    test_classes = [row[-1] for row in test_sample]\n",
    "    num_test_classes = len(test_classes)\n",
    "    test_labels = list(class_mappings.keys())\n",
    "\n",
    "    if len(test_classes) != len(algorithm_predictions):\n",
    "        raise IndexError(\"The count of test classes is not equal to the count of algorithm predictions!\")\n",
    "\n",
    "    num_correct_predictions = sum([actual == predicted for actual, predicted \n",
    "                                                        in zip(test_classes, algorithm_predictions)])\n",
    "\n",
    "    wrong_predictions = [f'A:{test_labels[actual]} | P:{test_labels[predicted]}'\n",
    "                                                            for actual, predicted \n",
    "                                                            in zip(test_classes, algorithm_predictions)\n",
    "                                                            if actual != predicted]\n",
    "                        \n",
    "    accuracy = (num_correct_predictions / num_test_classes) * 100\n",
    "    return accuracy, wrong_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts_Evaluate_kNN_Algorithm(dataset, class_mappings, test_ratio=0.25, \n",
    "                                                                num_neighbours=3, num_iterations=100):\n",
    "    \n",
    "    ACCURACY_HISTORY = []\n",
    "    WRONG_PREDICTION_HISTORY = []\n",
    "\n",
    "    for _iter in range(num_iterations):\n",
    "        _dataset = copy.deepcopy(dataset)\n",
    "        test_sample, train_sample = _test_train_split(_dataset, test_ratio)\n",
    "\n",
    "        algorithm_predictions = kNN_Algorithm(test_sample, train_sample, num_neighbours)\n",
    "        accuracy, wrong_predictions = _get_accuracy(test_sample, algorithm_predictions, class_mappings)\n",
    "        ACCURACY_HISTORY.append(accuracy)\n",
    "        WRONG_PREDICTION_HISTORY.extend(wrong_predictions)\n",
    "\n",
    "    random.shuffle(WRONG_PREDICTION_HISTORY)\n",
    "    print('kNN algorithm evaluation using the Test/Train Split method:', '\\n\\t', \n",
    "                'Average Accuracy:', round(statistics.mean(ACCURACY_HISTORY), ndigits=4), '\\n\\t', \n",
    "                'Maximum Accuracy:', max(ACCURACY_HISTORY), '\\n')\n",
    "\n",
    "    print('A: Actual | P: Predicted')\n",
    "    print('\\n'.join(WRONG_PREDICTION_HISTORY[:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvs_Evaluate_kNN_Algorithm(dataset, class_mappings, num_groups=5, \n",
    "                                                                num_neighbours=3, num_iterations=100):\n",
    "    \n",
    "    ACCURACY_HISTORY = []\n",
    "    WRONG_PREDICTION_HISTORY = []\n",
    "\n",
    "    for _iter in range(num_iterations):\n",
    "        _dataset = copy.deepcopy(dataset)\n",
    "        dataset_groups = _cross_validation_split(_dataset, num_groups)\n",
    "\n",
    "        for idx, group in enumerate(dataset_groups):\n",
    "            test_sample = group\n",
    "            _train_sample = copy.deepcopy(dataset_groups)\n",
    "            del _train_sample[idx]\n",
    "            \n",
    "            train_sample = []\n",
    "            for train_group in _train_sample:\n",
    "                train_sample.extend(train_group)\n",
    "\n",
    "            algorithm_predictions = kNN_Algorithm(test_sample, train_sample, num_neighbours)\n",
    "            accuracy, wrong_predictions = _get_accuracy(test_sample, algorithm_predictions, class_mappings)\n",
    "            ACCURACY_HISTORY.append(accuracy)\n",
    "            WRONG_PREDICTION_HISTORY.extend(wrong_predictions)\n",
    "\n",
    "    random.shuffle(WRONG_PREDICTION_HISTORY)\n",
    "    print('kNN algorithm evaluation using the Cross Validation Split method:', '\\n\\t', \n",
    "                'Average Accuracy:', round(statistics.mean(ACCURACY_HISTORY), ndigits=4), '\\n\\t', \n",
    "                'Maximum Accuracy:', max(ACCURACY_HISTORY), '\\n')\n",
    "\n",
    "    print('A: Actual | P: Predicted')\n",
    "    print('\\n'.join(WRONG_PREDICTION_HISTORY[:20]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate kNN Algorithm: Using Test-Train Split Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN algorithm evaluation using the Test/Train Split method: \n",
      "\t Average Accuracy: 94.8649 \n",
      "\t Maximum Accuracy: 100.0 \n",
      "\n",
      "A: Actual | P: Predicted\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "dataset, class_mappings = DataLoader(\"IrisData.csv\")\n",
    "tts_Evaluate_kNN_Algorithm(dataset, class_mappings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate kNN Algorithm: Using Cross-Validation Split Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN algorithm evaluation using the Cross Validation Split method: \n",
      "\t Average Accuracy: 95.22 \n",
      "\t Maximum Accuracy: 100.0 \n",
      "\n",
      "A: Actual | P: Predicted\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-virginica | P:Iris-versicolor\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-versicolor | P:Iris-virginica\n",
      "A:Iris-virginica | P:Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "dataset, class_mappings = DataLoader(\"IrisData.csv\")\n",
    "cvs_Evaluate_kNN_Algorithm(dataset, class_mappings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources & References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  [Develop k-Nearest Neighbors in Python From Scratch - Machine Learning Mastery](https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/)\n",
    "\n",
    "-  [K Nearest Neighbors Algorithm using Python From Absolute Scratch - The Nerdy Dev](https://www.youtube.com/watch?v=uclqpQe8TMQ)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64ed01536bf604a35b39c8ffb5f8754e0194885370844d2a99bdfd2c5ccd0baa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
